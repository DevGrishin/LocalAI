# LocalAI

LocalAI is a C++/Qt 6 application that provides a ChatGPT-style interface to interact with local AI models using [Ollama](https://ollama.ai). It leverages QML for the UI and supports modern local LLMs with minimal overhead.

---

## ğŸš€ Features

- Local AI chat interface
- Modern QML-based GUI
- Integration with Ollama for local model inference

---

## ğŸ§° Prerequisites

### âœ… Qt 6.5 or newer

Install Qt with the following modules:

- `Qt Quick`
- `Qt Sql`

You can install via [Qt Online Installer](https://www.qt.io/download) or through your package manager.

### âœ… CMake 3.16 or newer

Install CMake:

- On Linux: `sudo apt install cmake`
- On macOS: `brew install cmake`
- On Windows: via [cmake.org](https://cmake.org/download/)

### âœ… Compiler

Youâ€™ll need a C++17-compatible compiler (GCC, Clang, or MSVC).

---

## ğŸ§  Install Ollama

LocalAI requires [Ollama](https://ollama.ai) to run local language models.

1. Download and install Ollama from [https://ollama.ai](https://ollama.ai)
2. Start Ollama (it typically runs as a background service)
3. Pull a model:
   ```bash
   ollama pull llama2
   ```
   or a smaller version:
   ```bash
   ollama pull llama2:7b
   ```

---

## ğŸ”§ Building the Project

### Clone the repository

```bash
git clone https://github.com/your-username/LocalAI.git
cd LocalAI
```

### Configure and build

```bash
mkdir build
cd build
cmake ..
cmake --build .
```

> ğŸ’¡ If Qt isnâ€™t found automatically, you may need to set `CMAKE_PREFIX_PATH`:
> ```bash
> export CMAKE_PREFIX_PATH=/path/to/Qt/6.5.0/gcc_64/lib/cmake
> ```

---

## â–¶ï¸ Running the App

From the `build/` directory:

```bash
./appLocalAI
```

(On Windows: `appLocalAI.exe`)

---

## ğŸ“ Project Structure

```
LocalAI/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ main.cpp
â”œâ”€â”€ Main.qml
â”œâ”€â”€ Label.qml
â”œâ”€â”€ HistoryItem.qml
â”œâ”€â”€ AiHandler.h / .cpp
â””â”€â”€ ollama.hpp
```

---

## ğŸ“¦ Installation (Optional)

To install the application system-wide (e.g., on Linux):

```bash
cmake --install .
```

---

## ğŸ“¤ Deployment Notes

You may need to bundle Qt runtime libraries when distributing:

- **Linux**: Use `linuxdeployqt`
- **Windows**: Use `windeployqt`
- **macOS**: Use `macdeployqt`

---
